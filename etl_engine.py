import pandas as pd
from sqlalchemy import create_engine
from urllib.parse import quote_plus
from io import BytesIO

# --- CONFIG ---
# ‡πÅ‡∏Å‡πâ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
db_password = quote_plus("teezaza123") 
DB_CONNECTION_STR = f'postgresql://postgres:{db_password}@localhost:5432/safety_db'

def _process_dataframe(df, batch_id=None):
    # CLEAN HEADERS: ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤-‡∏´‡∏•‡∏±‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå + ‡∏•‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
    df.columns = df.columns.str.strip().str.replace(r"\s+", " ", regex=True)

    # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏Å‡∏î/‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á
    alias_mapping = {
        '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£': 'document_date',
        '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô/‡∏õ‡∏µ': '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô/‡∏õ‡∏µ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£',
        '‡∏ä‡∏∑‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô': '‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô',
        '% ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î': '%‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î',
        '% ‡∏•‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏¥‡∏•': '%‡∏•‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏¥‡∏•',
        '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢ ‡∏î': '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î',
        '‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î %': '‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î%',
        '‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î % ': '‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î%',
        '‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î %/': '‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î%'
    }
    df = df.rename(columns=alias_mapping)

    # 2. RENAME: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    column_mapping = {
        '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£': 'document_date',
        '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô/‡∏õ‡∏µ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£': 'document_date',
        'DATE': 'document_date',
        'DATEDOC': 'document_date',
        'Duc': 'document_date',
        '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ö‡∏¥‡∏•': 'invoice_no',
        'INV': 'invoice_no',
        'DOCNO': 'invoice_no',
        '‡∏£‡∏´‡∏±‡∏™‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤/‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤': 'customer_code_name',
        '‡∏£‡∏´‡∏±‡∏™‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤': 'customer_code',
        '‡∏£‡∏´‡∏±‡∏™‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤.1': 'customer_code',
        'ACCID': 'customer_code',
        '‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤': 'customer_name',
        'XCOMP': 'customer_name',
        '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î': 'province',
        '‡∏£‡∏´‡∏±‡∏™‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢': 'sales_rep_code',
        '‡∏£‡∏´‡∏±‡∏™‡∏ú‡∏π‡πâ‡πÅ‡∏ó‡∏ô': 'sales_rep_code',
        'ID': 'sales_rep_code',
        'ID_EM': 'sales_rep_code',
        '‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô': 'sales_rep_name',
        '‡∏ú‡∏π‡πâ‡πÅ‡∏ó‡∏ô': 'sales_rep_name',
        'SNAME': 'sales_rep_name',
        '‡∏ó‡∏µ‡∏°': 'sales_team',
        'TEAM': 'sales_team',
        'TEAMID': 'sales_team',
        'TEAMDESC': 'sales_team',
        '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤': 'product_code',
        '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤': 'product_group',
        '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î': 'product_name',
        '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤': 'product_name',
        'XDESC': 'product_name',
        '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô': 'quantity',
        '‡∏à‡∏ô': 'quantity',
        'QUAN': 'quantity',
        '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ô‡∏±‡∏ö': 'unit_of_measure',
        'UNIT': 'unit_of_measure',
        '@': 'unit_price',
        '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢': 'unit_price',
        'PRICE': 'unit_price',
        '%‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î': 'discount_percent',
        '‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î%': 'discount_percent',
        'DISCL': 'discount_percent',
        '%‡∏•‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏¥‡∏•': 'bill_discount_percent',
        'DISCD': 'bill_discount_percent',
        '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏•‡∏∞ NON VAT': 'unit_price_non_vat',
        '‡∏£‡∏ß‡∏°‡πÄ‡∏á‡∏¥‡∏ô NON VAT': 'total_amount_non_vat',
        'INVAMT': 'total_amount_non_vat',
        'XNET': 'total_amount_non_vat',
        '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ß‡∏°vat': 'total_amount_non_vat',
        'VPRICE': 'total_amount_non_vat'
    }

    df = df.rename(columns=column_mapping)

    # ‡∏Å‡∏±‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥‡∏´‡∏•‡∏±‡∏á rename
    df = df.loc[:, ~df.columns.duplicated()]

    # ‡πÉ‡∏ä‡πâ‡∏£‡∏´‡∏±‡∏™/‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏ß‡∏° ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏•‡∏±‡∏Å‡∏ß‡πà‡∏≤‡∏á
    if 'customer_code_name' in df.columns:
        def _split_customer_code_name(value):
            if pd.isna(value):
                return None, None
            text_value = str(value).strip()
            if not text_value:
                return None, None
            if ':' in text_value:
                code, name = text_value.split(':', 1)
                return code.strip() or None, name.strip() or None
            return None, text_value

        extracted = df['customer_code_name'].apply(_split_customer_code_name)
        df['customer_code_from_name'] = extracted.map(lambda x: x[0])
        df['customer_name_from_name'] = extracted.map(lambda x: x[1])

        if 'customer_code' not in df.columns:
            df['customer_code'] = df['customer_code_from_name']
        else:
            df['customer_code'] = df['customer_code'].fillna(df['customer_code_from_name'])

        if 'customer_name' not in df.columns:
            df['customer_name'] = df['customer_name_from_name']
        else:
            df['customer_name'] = df['customer_name'].fillna(df['customer_name_from_name'])

        df = df.drop(columns=['customer_code_name', 'customer_code_from_name', 'customer_name_from_name'])

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
    valid_cols = list(column_mapping.values())
    final_cols = df.columns.intersection(valid_cols)
    df = df[final_cols]

    # 3. CLEAN DATA (‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç!)
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    if 'document_date' in df.columns:
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡∏ñ‡πâ‡∏≤‡∏ä‡πà‡∏≠‡∏á‡πÑ‡∏´‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô NaT (‡∏ß‡πà‡∏≤‡∏á)
        df['document_date'] = pd.to_datetime(df['document_date'], dayfirst=True, errors='coerce')
        
        # --- [‡∏à‡∏∏‡∏î‡∏Ü‡πà‡∏≤‡∏ö‡∏±‡πä‡∏Å] ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏õ‡πÄ‡∏•‡∏¢ ---
        print(f"üîé ‡πÄ‡∏à‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df)} ‡πÅ‡∏ñ‡∏ß")
        df = df.dropna(subset=['document_date'])
        print(f"üßπ ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏´‡∏•‡∏∑‡∏≠: {len(df)} ‡πÅ‡∏ñ‡∏ß")

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô 0)
    numeric_cols = ['quantity', 'unit_price', 'total_amount_non_vat', 
                   'discount_percent', 'bill_discount_percent', 'unit_price_non_vat']
    
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # 4. LOAD TO DATABASE
    if batch_id:
        df["batch_id"] = batch_id
    if len(df) > 0:
        engine = create_engine(DB_CONNECTION_STR)
        with engine.connect() as conn:
             df.to_sql('sales_transactions', engine, index=False, if_exists='append')
        
        print(f"‚úÖ Success! ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(df)} ‡πÅ‡∏ñ‡∏ß")
        return True, len(df)
    else:
        print("‚ö†Ô∏è Warning: ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏•‡∏¢ (‡∏≠‡∏≤‡∏à‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î Format ‡∏´‡∏°‡∏î)")
        return False, 0

def process_excel_file(file_path):
    print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {file_path} ...")
    
    try:
        # 1. ‡∏≠‡πà‡∏≤‡∏ô Excel
        xl = pd.ExcelFile(file_path)
        preferred_sheets = ["DATA ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡∏ï", "DATA FULL", "2025", "2024"]
        sheet = next((s for s in preferred_sheets if s in xl.sheet_names), xl.sheet_names[0])
        df = xl.parse(sheet)
        success, _ = _process_dataframe(df)
        return success

    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

def process_excel_bytes(file_bytes, batch_id=None):
    try:
        xl = pd.ExcelFile(BytesIO(file_bytes))
        preferred_sheets = ["DATA ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡∏ï", "DATA FULL", "2025", "2024"]
        sheet = next((s for s in preferred_sheets if s in xl.sheet_names), xl.sheet_names[0])
        df = xl.parse(sheet)
        success, rows = _process_dataframe(df, batch_id=batch_id)
        return {"success": success, "rows": rows}
    except Exception as e:
        return {"success": False, "rows": 0, "error": str(e)}